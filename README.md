# Swapping-In-Depth


## A Practical Overview of Face Swapping Architecture

Before diving into the architecture of face swapping, it's important to understand the underlying complexities that justify the existence of each module. Variations in lighting, camera angles, occlusion (e.g., hands, hair, objects), motion blur, and subject distance all challenge facial fidelity. These real-world challenges require a modular system that adapts frame by frame. This is why modern face swapping solutions rely on multiple coordinated components rather than a single model.

---

### üöÄ New to Face Swapping?

If you're just starting out and feeling overwhelmed, you're not alone. We've created a beginner-friendly guide that walks you through real-world settings, tools, and terminology based on personal experience. It‚Äôs a great place to build a solid foundation before diving deeper into the architecture.

üëâ [Getting Started with Swapping ‚Äî My Experience](./GettingStartedWithSwapping-MyExperience.md)

---

### 1. üîç Detection  
**Purpose**: Identify and localize faces within each frame.  
**Examples**: RetinaFace, YOLOv8, SCRFD, YuNet  
**Output**: Bounding boxes + facial landmarks.

[See FaceDetectionOverview.md](./FaceDetectionOverview.md)

| Model     | Angle Tolerance      | Clarity Tolerance        | Speed       | Accuracy   |
|-----------|----------------------|---------------------------|-------------|------------|
| RetinaFace | Moderate            | High (blur/occlusion)     | Medium      | High       |
| YOLOv8     | Good (multi-object) | Medium                    | Fast        | High       |
| SCRFD      | Excellent           | Excellent                 | Medium-Fast | Very High  |
| YuNet      | Poor                | Low                       | Very Fast   | Low-Medium |

**Considerations**:
- **Angle tolerance**: SCRFD is best at handling varied head poses.
- **Clarity tolerance**: RetinaFace and SCRFD are strong under occlusion and blur.
- **Performance**: YuNet is lightweight but can miss nuanced cases.

---

### 2. üß† Recognition  
**Purpose**: Encode facial identity for matching or swapping.  
**Examples**: Inswapper128ArcFace, SimSwapArcFace, GhostArcFace, CSCSArcFace  
**Output**: Embedding vectors (latent representations of identity).

[See FaceRecognitionOverview.md](./FaceRecognitionOverview.md)

| Model             | Strengths                       | Limitations                           |
|------------------|----------------------------------|----------------------------------------|
| Inswapper128ArcFace | High consistency & reliability | Struggles with extreme close-ups       |
| SimSwapArcFace     | Well-tuned for stylistic swaps | Less stable across frames              |
| GhostArcFace       | Lightweight & decent identity  | May ghost in occluded environments     |
| CSCSArcFace        | Context-aware embedding logic  | Experimental, less widespread adoption |

**Considerations**:
- Maintain consistent embeddings across frames to avoid identity drift.
- Use robust models like InSwapper for stable identities under varied angles.

---

### 3. üß¨ Parsing / Restoration  
**Purpose**: Restore, align, or stylize faces‚Äîoften includes subtle transformations.  
**Examples**:  
- *Restorers*: GFPGAN, CodeFormer, RestorerFormer++, VQFT-v2  
- *Alignments*: Original / Blend / Reference  

[See FaceParsersOverview.md](./FaceParsersOverview.md)

**Output**: Enhanced face textures that preserve identity and motion consistency.  

| Use Case           | Suggested Setup                                                                 |
|--------------------|----------------------------------------------------------------------------------|
| Fast movement      | RestorerFormer++ with Blend alignment                                           |
| Close-up shots     | VQFT-v2 with Blend or Reference alignment, higher fidelity weight               |
| Subject likeness   | GFPGAN with Original alignment, low fidelity weight                             |
| Artistic/stylized  | CodeFormer with Blend or Reference alignment                                    |

**Dual Parser Strategies**:
- **Vary by distance**: Use a lightweight parser for distant or fast-moving shots; use a heavier parser like VQFT-v2 for close-ups.
- **Vary by fidelity need**: Lower fidelity weight with "Original" for preserving subject integrity; higher weight with "Blend" for stylistic consistency.
- **Performance tip**: Use RestorerFormer++ for responsive real-time needs, and VQFT for static or final-pass rendering.

---

### 4. üé≠ Composition & Swapping Logic  
**Purpose**: Apply face identity to the detected region, blend with original footage.  
**Includes**:
- Face mask generation  
- Warping and morphing  
- Color correction and shadow integration  
- Motion compensation  

**Output**: Seamlessly swapped face in the original video context.  
**Challenges**: Matching skin tones, correcting for lens distortion, and preserving expression dynamics.

[See CompositionAndSwappingOverview.md](./CompositionAndSwappingOverview.md)

---

### 5. üß≠ Temporal Consistency & Tracking (Essential for Video)  
**Purpose**: Maintain identity, alignment, and visual quality across time.  
**Techniques**:
- Optical flow  
- Landmark tracking  
- Frame-to-frame interpolation  

**Tools**: Some pipelines include their own tracking logic or pair with trackers like DeepSort or FairFaceTrack.  
**Goal**: Avoid flickering, jittering, or face misalignment during playback.

[See TemporalConsistencyAndTrackingOverview.md](./TemporalConsistencyAndTracking.md)




